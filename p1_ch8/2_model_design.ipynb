{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7cda287-e00d-4ab7-9f6e-319c1ba1ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\envs\\yolo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x210c498ae88>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.set_printoptions(edgeitems=3, linewidth=120)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e8157-6d01-4e00-80b1-5d682b03408e",
   "metadata": {},
   "source": [
    "# 准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02752e-e76d-442b-bd50-a549b5a8e3db",
   "metadata": {},
   "source": [
    "## 提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d154d6e-acb9-46d8-9d14-6b90d0fefd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', \n",
    "               'frog', 'horse', 'ship', 'truck']\n",
    "data_path = 'data/'\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]\n",
    "\n",
    "len(cifar10), len(cifar2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14ef12-1cce-48fa-93ac-02217e0f2540",
   "metadata": {},
   "source": [
    "## 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4db0b72-2e58-419c-b85c-865e8f8713e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, model, optimizer, loss_fn, train_loader):\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        each_epoch_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            each_epoch_loss += loss\n",
    "    \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")[: -4]\n",
    "        if epoch in {1, 2, 3, 4, 5} or epoch % 20 == 0:\n",
    "            print(f'[Epoch: {epoch}] at {current_time} \\nTraining Loss: {each_epoch_loss / len(train_loader):.4f}')\n",
    "        if epoch == 6:\n",
    "            print('    ...    ...   ...   ...   ...   ')\n",
    "        if epoch % 20 == 1 and epoch != 1:\n",
    "            print('    ...    ...   ...   ...   ...   ')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935d551-8839-49df-b8da-a58d47ef1b19",
   "metadata": {},
   "source": [
    "## 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3adbcdc-862b-45e0-89b9-ce0a3619fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader, model_name, loader_name='Validation'):\n",
    "    \n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            \n",
    "            imgs   = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((preds == labels).sum())\n",
    "    \n",
    "    correct_rate = correct / total\n",
    "    print(f'Accuracy of Model [{model_name}] on [{loader_name}] set is {correct_rate:.4f}')\n",
    "    return correct_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09251ea-d94a-4fab-a78f-fbceb9d90945",
   "metadata": {},
   "source": [
    "# 加宽模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bbd0e-03d9-4098-92cb-f5fe195901ff",
   "metadata": {},
   "source": [
    "## 模型*WidenNet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb7da56-d0ba-478c-98a7-3704c8f44650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WidenNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(3, 3), padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 16 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3603f4-a583-4977-a5ac-1455776e3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WidenNet(nn.Module):\n",
    "    def __init__(self, in_channels1=3, out_channels1=32):\n",
    "        super().__init__()\n",
    "        self.in_channels2  = out_channels1\n",
    "        self.out_channels2 = out_channels1 // 2\n",
    "        self.conv1 = nn.Conv2d(in_channels1, out_channels1, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.in_channels2, self.out_channels2, kernel_size=(3, 3), padding=1)\n",
    "        self.fc1 = nn.Linear(self.out_channels2 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, self.out_channels2 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8a534-8d02-430b-a2c8-4d1ad3c5dbe3",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5f4299-7f63-4b31-9a53-ef642f2fe504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [WidenNet] on deivce [cuda]... ...\n",
      "[Epoch: 1] at 2023-07-27 10:54:47.20 \n",
      "Training Loss: 0.5662\n",
      "[Epoch: 2] at 2023-07-27 10:54:48.60 \n",
      "Training Loss: 0.4752\n",
      "[Epoch: 3] at 2023-07-27 10:54:50.00 \n",
      "Training Loss: 0.4334\n",
      "[Epoch: 4] at 2023-07-27 10:54:51.41 \n",
      "Training Loss: 0.3907\n",
      "[Epoch: 5] at 2023-07-27 10:54:52.82 \n",
      "Training Loss: 0.3614\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 20] at 2023-07-27 10:55:13.91 \n",
      "Training Loss: 0.2649\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 40] at 2023-07-27 10:55:41.95 \n",
      "Training Loss: 0.2052\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 60] at 2023-07-27 10:56:09.94 \n",
      "Training Loss: 0.1644\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 80] at 2023-07-27 10:56:38.12 \n",
      "Training Loss: 0.1252\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 100] at 2023-07-27 10:57:06.32 \n",
      "Training Loss: 0.0905\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "model_name = 'WidenNet'\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training model [{model_name}] on deivce [{device}]... ...')\n",
    "\n",
    "widennet = WidenNet().to(device)\n",
    "optimizer = optim.SGD(widennet.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    \n",
    "    n_epochs,\n",
    "    widennet,\n",
    "    optimizer, \n",
    "    loss_fn,\n",
    "    train_loader\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76128d9e-30ce-491a-9566-1e9764b86660",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(widennet.state_dict(), 'model_parameters/widennet.pt')  # 只有模型的权重、没有结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08feac6-e1a8-4d4f-a9d2-1f5ac9f5c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model [WidenNet] on [Train] set is 0.9654\n",
      "Accuracy of Model [WidenNet] on [Validation] set is 0.8945\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "calculate_accuracy(widennet, train_loader, model_name, 'Train')\n",
    "calculate_accuracy(widennet, val_loader, model_name)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd0ae5-39b3-435c-ad4f-a77e5d4b5850",
   "metadata": {},
   "source": [
    "# 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aadead-33a3-4578-9b1e-c7256cd1158a",
   "metadata": {},
   "source": [
    "## 初始模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85df19c4-5046-41e4-bdbc-8f2c2514c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(3, 3), padding=1)\n",
    "        self.fc1   = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2   = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76269688-daec-4a31-9788-d69b8d807b60",
   "metadata": {},
   "source": [
    "## 修改训练函数中损失的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4c09a8-6104-44e0-bd9c-9db7567756f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_L2Reg(n_epochs, model, optimizer, loss_fn, train_loader):\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        each_epoch_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            L2_lambda = 0.001\n",
    "            L2_norm = sum(params.pow(2.0).sum()\n",
    "                          for params in model.parameters())\n",
    "            loss = loss + L2_lambda * L2_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            each_epoch_loss += loss.item()\n",
    "\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")[: -4]\n",
    "        if epoch in {1, 2, 3, 4, 5} or epoch % 20 == 0:\n",
    "            print(f'[Epoch: {epoch}] at {current_time} \\nTraining Loss: {each_epoch_loss / len(train_loader):.4f}')\n",
    "        if epoch == 6:\n",
    "            print('    ...    ...   ...   ...   ...   ')\n",
    "        if epoch % 20 == 1 and epoch != 1:\n",
    "            print('    ...    ...   ...   ...   ...   ')\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9d56c-55d4-43c3-887c-2e7703b80b5f",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d89590-7f3f-490e-bc17-ffd22be4db74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [Net] on deivce [cuda]... ...\n",
      "[Epoch: 1] at 2023-07-26 20:06:04.46 \n",
      "Training Loss: 0.5803\n",
      "[Epoch: 2] at 2023-07-26 20:06:05.40 \n",
      "Training Loss: 0.4978\n",
      "[Epoch: 3] at 2023-07-26 20:06:06.45 \n",
      "Training Loss: 0.4758\n",
      "[Epoch: 4] at 2023-07-26 20:06:07.54 \n",
      "Training Loss: 0.4567\n",
      "[Epoch: 5] at 2023-07-26 20:06:08.67 \n",
      "Training Loss: 0.4374\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 20] at 2023-07-26 20:06:21.95 \n",
      "Training Loss: 0.3264\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 40] at 2023-07-26 20:06:41.57 \n",
      "Training Loss: 0.2893\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 60] at 2023-07-26 20:07:02.46 \n",
      "Training Loss: 0.2597\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 80] at 2023-07-26 20:07:23.80 \n",
      "Training Loss: 0.2320\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 100] at 2023-07-26 20:07:41.12 \n",
      "Training Loss: 0.2139\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "model_name = 'Net'\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training model [{model_name}] on deivce [{device}]... ...')\n",
    "\n",
    "net = Net().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "training_loop_L2Reg(\n",
    "    \n",
    "    n_epochs,\n",
    "    net,\n",
    "    optimizer, \n",
    "    loss_fn,\n",
    "    train_loader\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8ed2901-7fad-4ee4-97af-834cc61d6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model_parameters/net_L2Reg.pt')  # 只有模型的权重、没有结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc05b363-efce-4f9b-81c6-bc93a9c6a460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model [Net] on [Train] set is 0.9303\n",
      "Accuracy of Model [Net] on [Validation] set is 0.8855\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "calculate_accuracy(net, train_loader, model_name, 'Train')\n",
    "calculate_accuracy(net, val_loader, model_name)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ace2b-afd1-4147-aa48-d8d48031c88f",
   "metadata": {},
   "source": [
    "# 随机清零神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee5677-9195-4103-afbb-23022a8b4bd2",
   "metadata": {},
   "source": [
    "## 添加*nn.Dropout*模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb4d3f3-a524-477e-a08f-3b986b34398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DropoutNet(nn.Module):\n",
    "    def __init__(self, in_channels1=3, out_channels1=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels2 = out_channels1\n",
    "        self.out_channels2 = out_channels1 // 2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels1, out_channels1, kernel_size=(3, 3), padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(self.in_channels2, self.out_channels2, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.out_channels2 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, self.out_channels2 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54823c-e793-4340-af4a-5509591c230a",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5654c76e-226e-4978-8c51-14fceb120e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [DropoutNet] on deivce [cuda]... ...\n",
      "[Epoch: 1] at 2023-07-26 20:17:46.08 \n",
      "Training Loss: 0.5744\n",
      "[Epoch: 2] at 2023-07-26 20:17:46.81 \n",
      "Training Loss: 0.4904\n",
      "[Epoch: 3] at 2023-07-26 20:17:47.51 \n",
      "Training Loss: 0.4646\n",
      "[Epoch: 4] at 2023-07-26 20:17:48.20 \n",
      "Training Loss: 0.4439\n",
      "[Epoch: 5] at 2023-07-26 20:17:48.93 \n",
      "Training Loss: 0.4170\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 20] at 2023-07-26 20:17:59.13 \n",
      "Training Loss: 0.3482\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 40] at 2023-07-26 20:18:13.48 \n",
      "Training Loss: 0.3099\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 60] at 2023-07-26 20:18:27.82 \n",
      "Training Loss: 0.2824\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 80] at 2023-07-26 20:18:42.42 \n",
      "Training Loss: 0.2594\n",
      "   ...    ...   ...   ...   ...   \n",
      "[Epoch: 100] at 2023-07-26 20:18:56.05 \n",
      "Training Loss: 0.2434\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "model_name = 'DropoutNet'\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training model [{model_name}] on deivce [{device}]... ...')\n",
    "\n",
    "dropoutnet = DropoutNet().to(device)\n",
    "optimizer = optim.SGD(dropoutnet.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    \n",
    "    n_epochs,\n",
    "    dropoutnet,\n",
    "    optimizer, \n",
    "    loss_fn,\n",
    "    train_loader\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2adc569f-0e76-4a95-bea5-cc3fc0689295",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dropoutnet.state_dict(), 'model_parameters/dropoutnet.pt')  # 只有模型的权重、没有结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb309a90-95c2-4aac-852e-10cb4f437df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model [DropoutNet] on [Train] set is 0.9000\n",
      "Accuracy of Model [DropoutNet] on [Validation] set is 0.8770\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "calculate_accuracy(dropoutnet, train_loader, model_name, 'Train')\n",
    "calculate_accuracy(dropoutnet, val_loader, model_name)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32329fb-7b15-48da-b552-a84d7659aa46",
   "metadata": {},
   "source": [
    "# 批量归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ba48a-bb30-480b-9469-9dd247b09d6f",
   "metadata": {},
   "source": [
    "## 添加*nn.BatchNorm*模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c977d4f4-43e1-4e87-8250-67b9d73d7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormNet(nn.Module):\n",
    "    def __init__(self, in_channels1=3, out_channels1=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels2 = out_channels1\n",
    "        self.out_channels2 = out_channels1 // 2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels1, out_channels1, kernel_size=(3, 3), padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=out_channels1)\n",
    "        self.conv2 = nn.Conv2d(self.in_channels2, self.out_channels2, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=self.out_channels2)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.out_channels2 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1, self.out_channels2 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb0cdd2-daaa-4d7f-aead-4c511c4cbd6c",
   "metadata": {},
   "source": [
    "##  训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceff8adc-2d8b-479e-8637-3e9a942edac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [BatchNormNet] on deivce [cuda]... ...\n",
      "[Epoch: 1] at 2023-07-26 20:30:49.42 \n",
      "Training Loss: 0.4588\n",
      "[Epoch: 2] at 2023-07-26 20:30:50.25 \n",
      "Training Loss: 0.3721\n",
      "[Epoch: 3] at 2023-07-26 20:30:51.11 \n",
      "Training Loss: 0.3459\n",
      "[Epoch: 4] at 2023-07-26 20:30:51.93 \n",
      "Training Loss: 0.3303\n",
      "[Epoch: 5] at 2023-07-26 20:30:52.77 \n",
      "Training Loss: 0.3199\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 20] at 2023-07-26 20:31:05.07 \n",
      "Training Loss: 0.2159\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 40] at 2023-07-26 20:31:21.45 \n",
      "Training Loss: 0.1312\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 60] at 2023-07-26 20:31:37.96 \n",
      "Training Loss: 0.0755\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 80] at 2023-07-26 20:31:54.14 \n",
      "Training Loss: 0.0405\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 100] at 2023-07-26 20:32:10.47 \n",
      "Training Loss: 0.0243\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "model_name = 'BatchNormNet'\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training model [{model_name}] on deivce [{device}]... ...')\n",
    "\n",
    "batchnormnet = BatchNormNet().to(device)\n",
    "optimizer = optim.SGD(batchnormnet.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    \n",
    "    n_epochs,\n",
    "    batchnormnet,\n",
    "    optimizer, \n",
    "    loss_fn,\n",
    "    train_loader\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab1c0ac-dcba-4ef3-8434-298a5348de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batchnormnet.state_dict(), 'model_parameters/batchnormnet.pt')  # 只有模型的权重、没有结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b54359a-ac01-4638-b2cb-72ca5c323c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model [BatchNormNet] on [Train] set is 0.9499\n",
      "Accuracy of Model [BatchNormNet] on [Validation] set is 0.8475\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "calculate_accuracy(batchnormnet, train_loader, model_name, 'Train')\n",
    "calculate_accuracy(batchnormnet, val_loader, model_name)    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9a533-81ef-41e0-bcab-d71522e31561",
   "metadata": {},
   "source": [
    "# 深化模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519dc2e6",
   "metadata": {},
   "source": [
    "## 增加卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f633582e-ad62-4405-92fc-83f4b79b0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepenNet(nn.Module):\n",
    "    def __init__(self, in_channels1=3, out_channels1=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels2  = out_channels1\n",
    "        self.out_channels2 = out_channels1 // 2\n",
    "        self.in_channels3  = out_channels1 // 2\n",
    "        self.out_channels3 = out_channels1 // 2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels1, out_channels1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.in_channels2, self.out_channels2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(self.in_channels3, self.out_channels3, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.out_channels3 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, self.out_channels3 * 4 * 4)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc43cc",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1760dd51-fd32-412c-b5e2-d6d1a2348738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [DeepenNet] on deivce [cuda]... ...\n",
      "[Epoch: 1] at 2023-07-26 20:34:10.31 \n",
      "Training Loss: 0.6911\n",
      "[Epoch: 2] at 2023-07-26 20:34:11.19 \n",
      "Training Loss: 0.6628\n",
      "[Epoch: 3] at 2023-07-26 20:34:11.93 \n",
      "Training Loss: 0.5931\n",
      "[Epoch: 4] at 2023-07-26 20:34:12.74 \n",
      "Training Loss: 0.5308\n",
      "[Epoch: 5] at 2023-07-26 20:34:13.60 \n",
      "Training Loss: 0.4955\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 20] at 2023-07-26 20:34:26.06 \n",
      "Training Loss: 0.3073\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 40] at 2023-07-26 20:34:43.12 \n",
      "Training Loss: 0.2359\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 60] at 2023-07-26 20:34:59.85 \n",
      "Training Loss: 0.1817\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 80] at 2023-07-26 20:35:16.78 \n",
      "Training Loss: 0.1313\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 100] at 2023-07-26 20:35:33.15 \n",
      "Training Loss: 0.0886\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "model_name = 'DeepenNet'\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training model [{model_name}] on deivce [{device}]... ...')\n",
    "\n",
    "deepennet = DeepenNet().to(device)\n",
    "optimizer = optim.SGD(deepennet.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    \n",
    "    n_epochs,\n",
    "    deepennet,\n",
    "    optimizer, \n",
    "    loss_fn,\n",
    "    train_loader\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d70b83-47dc-42cc-a1af-82f72faf31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(deepennet.state_dict(), 'model_parameters/deepennet.pt')  # 只有模型的权重、没有结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85626bb2-596d-47f2-8de7-81a1b6e60942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model [DeepenNet] on [Train] set is 0.9683\n",
      "Accuracy of Model [DeepenNet] on [Validation] set is 0.9050\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "calculate_accuracy(deepennet, train_loader, model_name, 'Train')\n",
    "calculate_accuracy(deepennet, val_loader, model_name)    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b8e5c-2ff0-41c7-bbee-5cf61ae11709",
   "metadata": {},
   "source": [
    "# 残差模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821bdbd2",
   "metadata": {},
   "source": [
    "## 整合输出\n",
    "- 将之前卷积层的输出和最后一层激活后的卷积一起池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730708c2-5cbc-4140-b850-4ef899cb15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels1=3, out_channels1=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels2  = out_channels1\n",
    "        self.out_channels2 = out_channels1 // 2\n",
    "        self.in_channels3  = out_channels1 // 2\n",
    "        self.out_channels3 = out_channels1 // 2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels1 ,out_channels1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.in_channels2, self.out_channels2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(self.in_channels3, self.out_channels3, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.out_channels3 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out2 = F.max_pool2d(torch.relu(self.conv2(out1)), 2)\n",
    "        out3 = F.max_pool2d(torch.relu(self.conv3(out2)) + out2, 2)\n",
    "        out3 = out3.view(-1, self.out_channels3 * 4 * 4)\n",
    "        out4 = torch.relu(self.fc1(out3))\n",
    "        out5 = self.fc2(out4)\n",
    "\n",
    "        return out5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e7839",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9fc2dd7-00d0-450a-b1b7-475d11e7d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [ResNet] on deivce [cuda]... ...\n",
      "[Epoch: 1] at 2023-07-26 20:39:13.34 \n",
      "Training Loss: 0.6302\n",
      "[Epoch: 2] at 2023-07-26 20:39:14.08 \n",
      "Training Loss: 0.5092\n",
      "[Epoch: 3] at 2023-07-26 20:39:15.04 \n",
      "Training Loss: 0.4323\n",
      "[Epoch: 4] at 2023-07-26 20:39:15.87 \n",
      "Training Loss: 0.3876\n",
      "[Epoch: 5] at 2023-07-26 20:39:16.72 \n",
      "Training Loss: 0.3644\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 20] at 2023-07-26 20:39:29.66 \n",
      "Training Loss: 0.2842\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 40] at 2023-07-26 20:39:46.94 \n",
      "Training Loss: 0.2184\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 60] at 2023-07-26 20:40:03.51 \n",
      "Training Loss: 0.1649\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 80] at 2023-07-26 20:40:20.37 \n",
      "Training Loss: 0.1204\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 100] at 2023-07-26 20:40:37.11 \n",
      "Training Loss: 0.0754\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "model_name = 'ResNet'\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training model [{model_name}] on deivce [{device}]... ...')\n",
    "\n",
    "resnet = ResNet().to(device)\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    \n",
    "    n_epochs,\n",
    "    resnet,\n",
    "    optimizer, \n",
    "    loss_fn,\n",
    "    train_loader\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b26995e-8ef9-444e-bc03-87584f1fdc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'model_parameters/resnet.pt')  # 只有模型的权重、没有结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c78775f-259b-475e-827c-47092423213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model [ResNet] on [Train] set is 0.9766\n",
      "Accuracy of Model [ResNet] on [Validation] set is 0.8995\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "calculate_accuracy(resnet, train_loader, model_name, 'Train')\n",
    "calculate_accuracy(resnet, val_loader, model_name)    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463d643-db5f-491b-a553-d28b6901a76d",
   "metadata": {},
   "source": [
    "# 更深的残差模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68de29a",
   "metadata": {},
   "source": [
    "## 构建残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13909a7a-5494-4530-8a94-bf92ff189da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(n_channels, n_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(num_features=n_channels)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batchnorm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batchnorm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batchnorm(out)\n",
    "        out = torch.relu(out)\n",
    "\n",
    "        return out + x\n",
    "\n",
    "    \n",
    "class DeepenResNet(nn.Module):\n",
    "    def __init__(self, n_channels=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=n_channels, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_channels=n_channels)])\n",
    "        )\n",
    "        self.fc1 = nn.Linear(n_channels * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, self.n_channels * 8 * 8)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae31bd",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d94d8e2-67d4-4f50-89e7-d1b770c1ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [DeepenResNet] on deivce [cuda]... ...\n",
      "[Epoch: 1] at 2023-07-27 10:58:17.95 \n",
      "Training Loss: 0.4709\n",
      "[Epoch: 2] at 2023-07-27 10:58:24.75 \n",
      "Training Loss: 0.3874\n",
      "[Epoch: 3] at 2023-07-27 10:58:31.54 \n",
      "Training Loss: 0.3520\n",
      "[Epoch: 4] at 2023-07-27 10:58:38.33 \n",
      "Training Loss: 0.3262\n",
      "[Epoch: 5] at 2023-07-27 10:58:45.16 \n",
      "Training Loss: 0.3101\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 20] at 2023-07-27 11:00:27.67 \n",
      "Training Loss: 0.1778\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 40] at 2023-07-27 11:02:43.95 \n",
      "Training Loss: 0.0608\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 60] at 2023-07-27 11:04:59.79 \n",
      "Training Loss: 0.0189\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 80] at 2023-07-27 11:07:16.23 \n",
      "Training Loss: 0.0051\n",
      "    ...    ...   ...   ...   ...   \n",
      "[Epoch: 100] at 2023-07-27 11:09:32.10 \n",
      "Training Loss: 0.0054\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 3e-3\n",
    "model_name = 'DeepenResNet'\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training model [{model_name}] on deivce [{device}]... ...')\n",
    "\n",
    "deepenresnet = DeepenResNet().to(device)\n",
    "optimizer = optim.SGD(deepenresnet.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    \n",
    "    n_epochs,\n",
    "    deepenresnet,\n",
    "    optimizer, \n",
    "    loss_fn,\n",
    "    train_loader\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91133290-98eb-4766-95fd-9e2bc7651a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(deepenresnet.state_dict(), 'model_parameters/deepenresnet.pt')  # 只有模型的权重、没有结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dcff330-4b17-4aea-a9fd-873d712fcc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model [DeepenResNet] on [Train] set is 0.9999\n",
      "Accuracy of Model [DeepenResNet] on [Validation] set is 0.8915\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "calculate_accuracy(deepenresnet, train_loader, model_name, 'Train')\n",
    "calculate_accuracy(deepenresnet, val_loader, model_name)    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81927828",
   "metadata": {},
   "source": [
    "# 对比模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d8a49e",
   "metadata": {},
   "source": [
    "## 计算模型在训练集和测试集上的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daef1b96-7eea-4fa7-8bf5-c089648510e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy on deivce [cuda]... ...\n",
      "\n",
      "Accuracy of Model [widennet] on [Train] set is 0.9654\n",
      "Accuracy of Model [widennet] on [Validation] set is 0.8945\n",
      "*-----------------------------------------------------------*\n",
      "Accuracy of Model [net_L2Reg] on [Train] set is 0.9303\n",
      "Accuracy of Model [net_L2Reg] on [Validation] set is 0.8855\n",
      "*-----------------------------------------------------------*\n",
      "Accuracy of Model [dropoutnet] on [Train] set is 0.8935\n",
      "Accuracy of Model [dropoutnet] on [Validation] set is 0.8725\n",
      "*-----------------------------------------------------------*\n",
      "Accuracy of Model [batchnormnet] on [Train] set is 0.9499\n",
      "Accuracy of Model [batchnormnet] on [Validation] set is 0.8475\n",
      "*-----------------------------------------------------------*\n",
      "Accuracy of Model [deepennet] on [Train] set is 0.9683\n",
      "Accuracy of Model [deepennet] on [Validation] set is 0.9050\n",
      "*-----------------------------------------------------------*\n",
      "Accuracy of Model [resnet] on [Train] set is 0.9766\n",
      "Accuracy of Model [resnet] on [Validation] set is 0.8995\n",
      "*-----------------------------------------------------------*\n",
      "Accuracy of Model [deepenresnet] on [Train] set is 0.9999\n",
      "Accuracy of Model [deepenresnet] on [Validation] set is 0.8915\n",
      "*-----------------------------------------------------------*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.9654, 0.9303, 0.8935, 0.9499, 0.9683, 0.9766, 0.9999],\n",
       " [0.8945, 0.8855, 0.8725, 0.8475, 0.905, 0.8995, 0.8915],\n",
       " array([[0.9654, 0.9303, 0.8935, 0.9499, 0.9683, 0.9766, 0.9999],\n",
       "        [0.8945, 0.8855, 0.8725, 0.8475, 0.905 , 0.8995, 0.8915]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = ['widennet.pt', 'net_L2Reg.pt', 'dropoutnet.pt', \n",
    "              'batchnormnet.pt', 'deepennet.pt', 'resnet.pt', 'deepenresnet.pt']\n",
    "nets = [WidenNet(), Net(), DropoutNet(), BatchNormNet(), DeepenNet(), ResNet(), DeepenResNet()]\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Calculating accuracy on deivce [{device}]... ...\\n')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader   = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "for net, file_name in zip(nets, file_names):\n",
    "    \n",
    "    model = net.to(device)\n",
    "    model_name = file_name[: -3]\n",
    "    model.load_state_dict(torch.load('model_parameters/' + file_name, map_location=device))\n",
    "    \n",
    "    train_accuracy.append(calculate_accuracy(net, train_loader, model_name, 'Train'))\n",
    "    val_accuracy.append(calculate_accuracy(net, val_loader, model_name))\n",
    "    print('*-----------------------------------------------------------*')\n",
    "\n",
    "    \n",
    "accuracy = np.array([train_accuracy, val_accuracy])\n",
    "train_accuracy, val_accuracy, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de014782",
   "metadata": {},
   "source": [
    "## 绘制柱状图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c6f2aee-c55d-4c6c-8ec6-f059270bbe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "model_names = [name.replace('.pt', '') for name in file_names]\n",
    "labels = ['Train', 'Validation']\n",
    "\n",
    "n_variables = 7\n",
    "n_bars = 2\n",
    "x = np.arange(n_variables) * n_bars\n",
    "width = .8\n",
    "adjust = [width * i \n",
    "          for i in [bar_loc - (n_bars - 1) / 2 for bar_loc in range(n_bars)]]\n",
    "colors = sns.cubehelix_palette(n_colors=n_bars, rot=-0.2, gamma=0.6)\n",
    "\n",
    "\n",
    "for (acc, adjust, color, label) in zip(accuracy, adjust, colors, labels):\n",
    "    \n",
    "    bar = ax.bar(x=x + adjust, height=acc, width=width, label=label,\n",
    "                 color=color, edgecolor='black', linewidth=1.8)\n",
    "    for rect in bar:\n",
    "        height = rect.get_height()\n",
    "        ax.text(x=rect.get_x() + rect.get_width() / 2, y=height, \n",
    "                s=str(round(height, 2)), ha='center', va='bottom')\n",
    "    \n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=18)\n",
    "ax.set_ylim(0.7, 1.06)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['left'].set_linewidth(1.8)\n",
    "ax.spines['bottom'].set_linewidth(1.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a49c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6483501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f377376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
